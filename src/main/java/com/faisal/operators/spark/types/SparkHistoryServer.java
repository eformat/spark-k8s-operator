package com.faisal.operators.spark.types;


import com.faisal.operators.EntityInfo;
import com.fasterxml.jackson.annotation.*;
import io.quarkus.runtime.annotations.RegisterForReflection;

import java.util.ArrayList;
import java.util.HashMap;
import java.util.List;
import java.util.Map;


/**
 * A Spark history server configuration
 */
@JsonInclude(JsonInclude.Include.NON_NULL)
@JsonPropertyOrder({
        "type",
        "sharedVolume",
        "sparkConfiguration",
        "remoteURI",
        "expose",
        "host",
        "customImage",
        "logDirectory",
        "updateInterval",
        "internalPort",
        "retainedApplications",
        "maxApplications",
        "provider",
        "kerberos",
        "cleaner",
        "endEventReparseChunkSize",
        "inProgressOptimization",
        "numReplayThreads",
        "maxDiskUsage",
        "persistentPath"
})
@RegisterForReflection
public class SparkHistoryServer
        extends EntityInfo {

    @JsonProperty("type")
    private SparkHistoryServer.Type type = SparkHistoryServer.Type.fromValue("sharedVolume");
    @JsonProperty("sharedVolume")
    private SharedVolume sharedVolume;
    @JsonProperty("sparkConfiguration")
    private List<SparkConfiguration> sparkConfiguration = new ArrayList<SparkConfiguration>();
    /**
     * s3 bucket or hdfs path
     */
    @JsonProperty("remoteURI")
    @JsonPropertyDescription("s3 bucket or hdfs path")
    private String remoteURI;
    /**
     * Should the operator also expose the service? For OpenShift the route is created, while for Kubernetes the Ingress object is created.
     */
    @JsonProperty("expose")
    @JsonPropertyDescription("Should the operator also expose the service? For OpenShift the route is created, while for Kubernetes the Ingress object is created.")
    private Boolean expose = false;
    /**
     * Custom dns hostname under which the Spark History server will be exposed. If not specified it should be generated by OpenShift route, for K8s the Ingress resource is created and it's up to the Ingress controller.
     */
    @JsonProperty("host")
    @JsonPropertyDescription("Custom dns hostname under which the Spark History server will be exposed. If not specified it should be generated by OpenShift route, for K8s the Ingress resource is created and it's up to the Ingress controller.")
    private String host = "";
    /**
     * Container image that will be used for the spark history server. It assumes the standard Spark distribution under /opt/spark
     */
    @JsonProperty("customImage")
    @JsonPropertyDescription("Container image that will be used for the spark history server. It assumes the standard Spark distribution under /opt/spark")
    private String customImage;
    /**
     * For the filesystem history provider, the URL to the directory containing application event logs to load. This can be a local file:// path, an HDFS path hdfs://namenode/shared/spark-logs or that of an alternative filesystem supported by the Hadoop APIs.
     */
    @JsonProperty("logDirectory")
    @JsonPropertyDescription("For the filesystem history provider, the URL to the directory containing application event logs to load. This can be a local file:// path, an HDFS path hdfs://namenode/shared/spark-logs or that of an alternative filesystem supported by the Hadoop APIs.")
    private String logDirectory = "file:/history/spark-events";
    /**
     * The period (seconds) at which the filesystem history provider checks for new or updated logs in the log directory. A shorter interval detects new applications faster, at the expense of more server load re-reading updated applications. As soon as an update has completed, listings of the completed and incomplete applications will reflect the changes.
     */
    @JsonProperty("updateInterval")
    @JsonPropertyDescription("The period (seconds) at which the filesystem history provider checks for new or updated logs in the log directory. A shorter interval detects new applications faster, at the expense of more server load re-reading updated applications. As soon as an update has completed, listings of the completed and incomplete applications will reflect the changes.")
    private Integer updateInterval = 10;
    /**
     * The port on pod to which the web interface of the history server binds. If exposed via Route or Ingress, this internal port will probably map to some other port.
     */
    @JsonProperty("internalPort")
    @JsonPropertyDescription("The port on pod to which the web interface of the history server binds. If exposed via Route or Ingress, this internal port will probably map to some other port.")
    private Integer internalPort = 18080;
    /**
     * The number of applications to retain UI data for in the cache. If this cap is exceeded, then the oldest applications will be removed from the cache. If an application is not in the cache, it will have to be loaded from disk if it is accessed from the UI.
     */
    @JsonProperty("retainedApplications")
    @JsonPropertyDescription("The number of applications to retain UI data for in the cache. If this cap is exceeded, then the oldest applications will be removed from the cache. If an application is not in the cache, it will have to be loaded from disk if it is accessed from the UI.")
    private Integer retainedApplications = 50;
    /**
     * The number of applications to display on the history summary page. Application UIs are still available by accessing their URLs directly even if they are not displayed on the history summary page.
     */
    @JsonProperty("maxApplications")
    @JsonPropertyDescription("The number of applications to display on the history summary page. Application UIs are still available by accessing their URLs directly even if they are not displayed on the history summary page.")
    private Integer maxApplications = 999999;
    /**
     * Name of the class implementing the application history backend. Currently there is only one implementation, provided by Spark, which looks for application logs stored in the file system.
     */
    @JsonProperty("provider")
    @JsonPropertyDescription("Name of the class implementing the application history backend. Currently there is only one implementation, provided by Spark, which looks for application logs stored in the file system.")
    private String provider = "org.apache.spark.deploy.history.FsHistoryProvider";
    @JsonProperty("kerberos")
    private Kerberos kerberos;
    @JsonProperty("cleaner")
    private Cleaner cleaner;
    /**
     * # of MB; How many bytes to parse at the end of log files looking for the end event. This is used to speed up generation of application listings by skipping unnecessary parts of event log files. It can be disabled by setting this config to 0.
     */
    @JsonProperty("endEventReparseChunkSize")
    @JsonPropertyDescription("# of MB; How many bytes to parse at the end of log files looking for the end event. This is used to speed up generation of application listings by skipping unnecessary parts of event log files. It can be disabled by setting this config to 0.")
    private Integer endEventReparseChunkSize = 1;
    /**
     * Enable optimized handling of in-progress logs. This option may leave finished applications that fail to rename their event logs listed as in-progress.
     */
    @JsonProperty("inProgressOptimization")
    @JsonPropertyDescription("Enable optimized handling of in-progress logs. This option may leave finished applications that fail to rename their event logs listed as in-progress.")
    private Boolean inProgressOptimization = true;
    /**
     * Number of threads that will be used by history server to process event logs. If empty, 25% of available cores will be used.
     */
    @JsonProperty("numReplayThreads")
    @JsonPropertyDescription("Number of threads that will be used by history server to process event logs. If empty, 25% of available cores will be used.")
    private String numReplayThreads;
    /**
     * # of GB; Maximum disk usage for the local directory where the cache application history information are stored.
     */
    @JsonProperty("maxDiskUsage")
    @JsonPropertyDescription("# of GB; Maximum disk usage for the local directory where the cache application history information are stored.")
    private Integer maxDiskUsage = 10;
    /**
     * Local directory where to cache application history data. If set, the history server will store application data on disk instead of keeping it in memory. The data written to disk will be re-used in the event of a history server restart.
     */
    @JsonProperty("persistentPath")
    @JsonPropertyDescription("Local directory where to cache application history data. If set, the history server will store application data on disk instead of keeping it in memory. The data written to disk will be re-used in the event of a history server restart.")
    private String persistentPath;
    @JsonIgnore
    private Map<String, Object> additionalProperties = new HashMap<String, Object>();

    @JsonProperty("type")
    public SparkHistoryServer.Type getType() {
        return type;
    }

    @JsonProperty("type")
    public void setType(SparkHistoryServer.Type type) {
        this.type = type;
    }

    @JsonProperty("sharedVolume")
    public SharedVolume getSharedVolume() {
        return sharedVolume;
    }

    @JsonProperty("sharedVolume")
    public void setSharedVolume(SharedVolume sharedVolume) {
        this.sharedVolume = sharedVolume;
    }

    @JsonProperty("sparkConfiguration")
    public List<SparkConfiguration> getSparkConfiguration() {
        return sparkConfiguration;
    }

    @JsonProperty("sparkConfiguration")
    public void setSparkConfiguration(List<SparkConfiguration> sparkConfiguration) {
        this.sparkConfiguration = sparkConfiguration;
    }

    /**
     * s3 bucket or hdfs path
     */
    @JsonProperty("remoteURI")
    public String getRemoteURI() {
        return remoteURI;
    }

    /**
     * s3 bucket or hdfs path
     */
    @JsonProperty("remoteURI")
    public void setRemoteURI(String remoteURI) {
        this.remoteURI = remoteURI;
    }

    /**
     * Should the operator also expose the service? For OpenShift the route is created, while for Kubernetes the Ingress object is created.
     */
    @JsonProperty("expose")
    public Boolean getExpose() {
        return expose;
    }

    /**
     * Should the operator also expose the service? For OpenShift the route is created, while for Kubernetes the Ingress object is created.
     */
    @JsonProperty("expose")
    public void setExpose(Boolean expose) {
        this.expose = expose;
    }

    /**
     * Custom dns hostname under which the Spark History server will be exposed. If not specified it should be generated by OpenShift route, for K8s the Ingress resource is created and it's up to the Ingress controller.
     */
    @JsonProperty("host")
    public String getHost() {
        return host;
    }

    /**
     * Custom dns hostname under which the Spark History server will be exposed. If not specified it should be generated by OpenShift route, for K8s the Ingress resource is created and it's up to the Ingress controller.
     */
    @JsonProperty("host")
    public void setHost(String host) {
        this.host = host;
    }

    /**
     * Container image that will be used for the spark history server. It assumes the standard Spark distribution under /opt/spark
     */
    @JsonProperty("customImage")
    public String getCustomImage() {
        return customImage;
    }

    /**
     * Container image that will be used for the spark history server. It assumes the standard Spark distribution under /opt/spark
     */
    @JsonProperty("customImage")
    public void setCustomImage(String customImage) {
        this.customImage = customImage;
    }

    /**
     * For the filesystem history provider, the URL to the directory containing application event logs to load. This can be a local file:// path, an HDFS path hdfs://namenode/shared/spark-logs or that of an alternative filesystem supported by the Hadoop APIs.
     */
    @JsonProperty("logDirectory")
    public String getLogDirectory() {
        return logDirectory;
    }

    /**
     * For the filesystem history provider, the URL to the directory containing application event logs to load. This can be a local file:// path, an HDFS path hdfs://namenode/shared/spark-logs or that of an alternative filesystem supported by the Hadoop APIs.
     */
    @JsonProperty("logDirectory")
    public void setLogDirectory(String logDirectory) {
        this.logDirectory = logDirectory;
    }

    /**
     * The period (seconds) at which the filesystem history provider checks for new or updated logs in the log directory. A shorter interval detects new applications faster, at the expense of more server load re-reading updated applications. As soon as an update has completed, listings of the completed and incomplete applications will reflect the changes.
     */
    @JsonProperty("updateInterval")
    public Integer getUpdateInterval() {
        return updateInterval;
    }

    /**
     * The period (seconds) at which the filesystem history provider checks for new or updated logs in the log directory. A shorter interval detects new applications faster, at the expense of more server load re-reading updated applications. As soon as an update has completed, listings of the completed and incomplete applications will reflect the changes.
     */
    @JsonProperty("updateInterval")
    public void setUpdateInterval(Integer updateInterval) {
        this.updateInterval = updateInterval;
    }

    /**
     * The port on pod to which the web interface of the history server binds. If exposed via Route or Ingress, this internal port will probably map to some other port.
     */
    @JsonProperty("internalPort")
    public Integer getInternalPort() {
        return internalPort;
    }

    /**
     * The port on pod to which the web interface of the history server binds. If exposed via Route or Ingress, this internal port will probably map to some other port.
     */
    @JsonProperty("internalPort")
    public void setInternalPort(Integer internalPort) {
        this.internalPort = internalPort;
    }

    /**
     * The number of applications to retain UI data for in the cache. If this cap is exceeded, then the oldest applications will be removed from the cache. If an application is not in the cache, it will have to be loaded from disk if it is accessed from the UI.
     */
    @JsonProperty("retainedApplications")
    public Integer getRetainedApplications() {
        return retainedApplications;
    }

    /**
     * The number of applications to retain UI data for in the cache. If this cap is exceeded, then the oldest applications will be removed from the cache. If an application is not in the cache, it will have to be loaded from disk if it is accessed from the UI.
     */
    @JsonProperty("retainedApplications")
    public void setRetainedApplications(Integer retainedApplications) {
        this.retainedApplications = retainedApplications;
    }

    /**
     * The number of applications to display on the history summary page. Application UIs are still available by accessing their URLs directly even if they are not displayed on the history summary page.
     */
    @JsonProperty("maxApplications")
    public Integer getMaxApplications() {
        return maxApplications;
    }

    /**
     * The number of applications to display on the history summary page. Application UIs are still available by accessing their URLs directly even if they are not displayed on the history summary page.
     */
    @JsonProperty("maxApplications")
    public void setMaxApplications(Integer maxApplications) {
        this.maxApplications = maxApplications;
    }

    /**
     * Name of the class implementing the application history backend. Currently there is only one implementation, provided by Spark, which looks for application logs stored in the file system.
     */
    @JsonProperty("provider")
    public String getProvider() {
        return provider;
    }

    /**
     * Name of the class implementing the application history backend. Currently there is only one implementation, provided by Spark, which looks for application logs stored in the file system.
     */
    @JsonProperty("provider")
    public void setProvider(String provider) {
        this.provider = provider;
    }

    @JsonProperty("kerberos")
    public Kerberos getKerberos() {
        return kerberos;
    }

    @JsonProperty("kerberos")
    public void setKerberos(Kerberos kerberos) {
        this.kerberos = kerberos;
    }

    @JsonProperty("cleaner")
    public Cleaner getCleaner() {
        return cleaner;
    }

    @JsonProperty("cleaner")
    public void setCleaner(Cleaner cleaner) {
        this.cleaner = cleaner;
    }

    /**
     * # of MB; How many bytes to parse at the end of log files looking for the end event. This is used to speed up generation of application listings by skipping unnecessary parts of event log files. It can be disabled by setting this config to 0.
     */
    @JsonProperty("endEventReparseChunkSize")
    public Integer getEndEventReparseChunkSize() {
        return endEventReparseChunkSize;
    }

    /**
     * # of MB; How many bytes to parse at the end of log files looking for the end event. This is used to speed up generation of application listings by skipping unnecessary parts of event log files. It can be disabled by setting this config to 0.
     */
    @JsonProperty("endEventReparseChunkSize")
    public void setEndEventReparseChunkSize(Integer endEventReparseChunkSize) {
        this.endEventReparseChunkSize = endEventReparseChunkSize;
    }

    /**
     * Enable optimized handling of in-progress logs. This option may leave finished applications that fail to rename their event logs listed as in-progress.
     */
    @JsonProperty("inProgressOptimization")
    public Boolean getInProgressOptimization() {
        return inProgressOptimization;
    }

    /**
     * Enable optimized handling of in-progress logs. This option may leave finished applications that fail to rename their event logs listed as in-progress.
     */
    @JsonProperty("inProgressOptimization")
    public void setInProgressOptimization(Boolean inProgressOptimization) {
        this.inProgressOptimization = inProgressOptimization;
    }

    /**
     * Number of threads that will be used by history server to process event logs. If empty, 25% of available cores will be used.
     */
    @JsonProperty("numReplayThreads")
    public String getNumReplayThreads() {
        return numReplayThreads;
    }

    /**
     * Number of threads that will be used by history server to process event logs. If empty, 25% of available cores will be used.
     */
    @JsonProperty("numReplayThreads")
    public void setNumReplayThreads(String numReplayThreads) {
        this.numReplayThreads = numReplayThreads;
    }

    /**
     * # of GB; Maximum disk usage for the local directory where the cache application history information are stored.
     */
    @JsonProperty("maxDiskUsage")
    public Integer getMaxDiskUsage() {
        return maxDiskUsage;
    }

    /**
     * # of GB; Maximum disk usage for the local directory where the cache application history information are stored.
     */
    @JsonProperty("maxDiskUsage")
    public void setMaxDiskUsage(Integer maxDiskUsage) {
        this.maxDiskUsage = maxDiskUsage;
    }

    /**
     * Local directory where to cache application history data. If set, the history server will store application data on disk instead of keeping it in memory. The data written to disk will be re-used in the event of a history server restart.
     */
    @JsonProperty("persistentPath")
    public String getPersistentPath() {
        return persistentPath;
    }

    /**
     * Local directory where to cache application history data. If set, the history server will store application data on disk instead of keeping it in memory. The data written to disk will be re-used in the event of a history server restart.
     */
    @JsonProperty("persistentPath")
    public void setPersistentPath(String persistentPath) {
        this.persistentPath = persistentPath;
    }

    @JsonAnyGetter
    public Map<String, Object> getAdditionalProperties() {
        return this.additionalProperties;
    }

    @JsonAnySetter
    public void setAdditionalProperty(String name, Object value) {
        this.additionalProperties.put(name, value);
    }

    @Override
    public String toString() {
        StringBuilder sb = new StringBuilder();
        sb.append(SparkHistoryServer.class.getName()).append('@').append(Integer.toHexString(System.identityHashCode(this))).append('[');
        int baseLength = sb.length();
        String superString = super.toString();
        if (superString != null) {
            int contentStart = superString.indexOf('[');
            int contentEnd = superString.lastIndexOf(']');
            if ((contentStart >= 0) && (contentEnd > contentStart)) {
                sb.append(superString, (contentStart + 1), contentEnd);
            } else {
                sb.append(superString);
            }
        }
        if (sb.length() > baseLength) {
            sb.append(',');
        }
        sb.append("type");
        sb.append('=');
        sb.append(((this.type == null) ? "<null>" : this.type));
        sb.append(',');
        sb.append("sharedVolume");
        sb.append('=');
        sb.append(((this.sharedVolume == null) ? "<null>" : this.sharedVolume));
        sb.append(',');
        sb.append("sparkConfiguration");
        sb.append('=');
        sb.append(((this.sparkConfiguration == null) ? "<null>" : this.sparkConfiguration));
        sb.append(',');
        sb.append("remoteURI");
        sb.append('=');
        sb.append(((this.remoteURI == null) ? "<null>" : this.remoteURI));
        sb.append(',');
        sb.append("expose");
        sb.append('=');
        sb.append(((this.expose == null) ? "<null>" : this.expose));
        sb.append(',');
        sb.append("host");
        sb.append('=');
        sb.append(((this.host == null) ? "<null>" : this.host));
        sb.append(',');
        sb.append("customImage");
        sb.append('=');
        sb.append(((this.customImage == null) ? "<null>" : this.customImage));
        sb.append(',');
        sb.append("logDirectory");
        sb.append('=');
        sb.append(((this.logDirectory == null) ? "<null>" : this.logDirectory));
        sb.append(',');
        sb.append("updateInterval");
        sb.append('=');
        sb.append(((this.updateInterval == null) ? "<null>" : this.updateInterval));
        sb.append(',');
        sb.append("internalPort");
        sb.append('=');
        sb.append(((this.internalPort == null) ? "<null>" : this.internalPort));
        sb.append(',');
        sb.append("retainedApplications");
        sb.append('=');
        sb.append(((this.retainedApplications == null) ? "<null>" : this.retainedApplications));
        sb.append(',');
        sb.append("maxApplications");
        sb.append('=');
        sb.append(((this.maxApplications == null) ? "<null>" : this.maxApplications));
        sb.append(',');
        sb.append("provider");
        sb.append('=');
        sb.append(((this.provider == null) ? "<null>" : this.provider));
        sb.append(',');
        sb.append("kerberos");
        sb.append('=');
        sb.append(((this.kerberos == null) ? "<null>" : this.kerberos));
        sb.append(',');
        sb.append("cleaner");
        sb.append('=');
        sb.append(((this.cleaner == null) ? "<null>" : this.cleaner));
        sb.append(',');
        sb.append("endEventReparseChunkSize");
        sb.append('=');
        sb.append(((this.endEventReparseChunkSize == null) ? "<null>" : this.endEventReparseChunkSize));
        sb.append(',');
        sb.append("inProgressOptimization");
        sb.append('=');
        sb.append(((this.inProgressOptimization == null) ? "<null>" : this.inProgressOptimization));
        sb.append(',');
        sb.append("numReplayThreads");
        sb.append('=');
        sb.append(((this.numReplayThreads == null) ? "<null>" : this.numReplayThreads));
        sb.append(',');
        sb.append("maxDiskUsage");
        sb.append('=');
        sb.append(((this.maxDiskUsage == null) ? "<null>" : this.maxDiskUsage));
        sb.append(',');
        sb.append("persistentPath");
        sb.append('=');
        sb.append(((this.persistentPath == null) ? "<null>" : this.persistentPath));
        sb.append(',');
        sb.append("additionalProperties");
        sb.append('=');
        sb.append(((this.additionalProperties == null) ? "<null>" : this.additionalProperties));
        sb.append(',');
        if (sb.charAt((sb.length() - 1)) == ',') {
            sb.setCharAt((sb.length() - 1), ']');
        } else {
            sb.append(']');
        }
        return sb.toString();
    }

    @Override
    public int hashCode() {
        int result = 1;
        result = ((result * 31) + ((this.sparkConfiguration == null) ? 0 : this.sparkConfiguration.hashCode()));
        result = ((result * 31) + ((this.internalPort == null) ? 0 : this.internalPort.hashCode()));
        result = ((result * 31) + ((this.sharedVolume == null) ? 0 : this.sharedVolume.hashCode()));
        result = ((result * 31) + ((this.cleaner == null) ? 0 : this.cleaner.hashCode()));
        result = ((result * 31) + ((this.maxDiskUsage == null) ? 0 : this.maxDiskUsage.hashCode()));
        result = ((result * 31) + ((this.kerberos == null) ? 0 : this.kerberos.hashCode()));
        result = ((result * 31) + ((this.type == null) ? 0 : this.type.hashCode()));
        result = ((result * 31) + ((this.expose == null) ? 0 : this.expose.hashCode()));
        result = ((result * 31) + ((this.numReplayThreads == null) ? 0 : this.numReplayThreads.hashCode()));
        result = ((result * 31) + ((this.endEventReparseChunkSize == null) ? 0 : this.endEventReparseChunkSize.hashCode()));
        result = ((result * 31) + ((this.maxApplications == null) ? 0 : this.maxApplications.hashCode()));
        result = ((result * 31) + ((this.logDirectory == null) ? 0 : this.logDirectory.hashCode()));
        result = ((result * 31) + ((this.updateInterval == null) ? 0 : this.updateInterval.hashCode()));
        result = ((result * 31) + ((this.retainedApplications == null) ? 0 : this.retainedApplications.hashCode()));
        result = ((result * 31) + ((this.remoteURI == null) ? 0 : this.remoteURI.hashCode()));
        result = ((result * 31) + ((this.provider == null) ? 0 : this.provider.hashCode()));
        result = ((result * 31) + ((this.persistentPath == null) ? 0 : this.persistentPath.hashCode()));
        result = ((result * 31) + ((this.host == null) ? 0 : this.host.hashCode()));
        result = ((result * 31) + ((this.customImage == null) ? 0 : this.customImage.hashCode()));
        result = ((result * 31) + ((this.inProgressOptimization == null) ? 0 : this.inProgressOptimization.hashCode()));
        result = ((result * 31) + ((this.additionalProperties == null) ? 0 : this.additionalProperties.hashCode()));
        result = ((result * 31) + super.hashCode());
        return result;
    }

    @Override
    public boolean equals(Object other) {
        if (other == this) {
            return true;
        }
        if ((other instanceof SparkHistoryServer) == false) {
            return false;
        }
        SparkHistoryServer rhs = ((SparkHistoryServer) other);
        return (((((((((((((((((((((super.equals(rhs) && ((this.sparkConfiguration == rhs.sparkConfiguration) || ((this.sparkConfiguration != null) && this.sparkConfiguration.equals(rhs.sparkConfiguration)))) && ((this.internalPort == rhs.internalPort) || ((this.internalPort != null) && this.internalPort.equals(rhs.internalPort)))) && ((this.sharedVolume == rhs.sharedVolume) || ((this.sharedVolume != null) && this.sharedVolume.equals(rhs.sharedVolume)))) && ((this.cleaner == rhs.cleaner) || ((this.cleaner != null) && this.cleaner.equals(rhs.cleaner)))) && ((this.maxDiskUsage == rhs.maxDiskUsage) || ((this.maxDiskUsage != null) && this.maxDiskUsage.equals(rhs.maxDiskUsage)))) && ((this.kerberos == rhs.kerberos) || ((this.kerberos != null) && this.kerberos.equals(rhs.kerberos)))) && ((this.type == rhs.type) || ((this.type != null) && this.type.equals(rhs.type)))) && ((this.expose == rhs.expose) || ((this.expose != null) && this.expose.equals(rhs.expose)))) && ((this.numReplayThreads == rhs.numReplayThreads) || ((this.numReplayThreads != null) && this.numReplayThreads.equals(rhs.numReplayThreads)))) && ((this.endEventReparseChunkSize == rhs.endEventReparseChunkSize) || ((this.endEventReparseChunkSize != null) && this.endEventReparseChunkSize.equals(rhs.endEventReparseChunkSize)))) && ((this.maxApplications == rhs.maxApplications) || ((this.maxApplications != null) && this.maxApplications.equals(rhs.maxApplications)))) && ((this.logDirectory == rhs.logDirectory) || ((this.logDirectory != null) && this.logDirectory.equals(rhs.logDirectory)))) && ((this.updateInterval == rhs.updateInterval) || ((this.updateInterval != null) && this.updateInterval.equals(rhs.updateInterval)))) && ((this.retainedApplications == rhs.retainedApplications) || ((this.retainedApplications != null) && this.retainedApplications.equals(rhs.retainedApplications)))) && ((this.remoteURI == rhs.remoteURI) || ((this.remoteURI != null) && this.remoteURI.equals(rhs.remoteURI)))) && ((this.provider == rhs.provider) || ((this.provider != null) && this.provider.equals(rhs.provider)))) && ((this.persistentPath == rhs.persistentPath) || ((this.persistentPath != null) && this.persistentPath.equals(rhs.persistentPath)))) && ((this.host == rhs.host) || ((this.host != null) && this.host.equals(rhs.host)))) && ((this.customImage == rhs.customImage) || ((this.customImage != null) && this.customImage.equals(rhs.customImage)))) && ((this.inProgressOptimization == rhs.inProgressOptimization) || ((this.inProgressOptimization != null) && this.inProgressOptimization.equals(rhs.inProgressOptimization)))) && ((this.additionalProperties == rhs.additionalProperties) || ((this.additionalProperties != null) && this.additionalProperties.equals(rhs.additionalProperties))));
    }

    public enum Type {

        sharedVolume("sharedVolume"),
        remoteStorage("remoteStorage");
        private final String value;
        private final static Map<String, SparkHistoryServer.Type> CONSTANTS = new HashMap<String, SparkHistoryServer.Type>();

        static {
            for (SparkHistoryServer.Type c : values()) {
                CONSTANTS.put(c.value, c);
            }
        }

        private Type(String value) {
            this.value = value;
        }

        @Override
        public String toString() {
            return this.value;
        }

        @JsonValue
        public String value() {
            return this.value;
        }

        @JsonCreator
        public static SparkHistoryServer.Type fromValue(String value) {
            SparkHistoryServer.Type constant = CONSTANTS.get(value);
            if (constant == null) {
                throw new IllegalArgumentException(value);
            } else {
                return constant;
            }
        }

    }

}
